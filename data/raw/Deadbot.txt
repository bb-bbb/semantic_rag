A deadbot, deathbot, or griefbot is a digital avatar, created with artificial intelligence, which resembles a person who is dead. GriefBots employ natural language processing and machine-learning techniques to approximate the style and personality of a deceased person. They may appear as chatbots, voice assistants, or animated avatars, and are often trained on an individual's  digital remains. The goal is to preserve memory, aid emotional coping, or maintain what psychologists call a “continuing bond” with the deceased. The phenomenon has generated debate about authenticity, consent, and the psychological effects of digitally extending personhood.
Among the earliest researchers, Muhammad Aurangzeb Ahmad of the University of Washington developed the "Grandpa Bot" project, a conversational simulation of his late father designed for his children to interact with. Other notable efforts include journalist James Vlahos's  Dadbot , which evolved into the commercial platform HereAfter AI, Hossein Rahnama's  Augmented Eternity  research at MIT Media Lab and Toronto Metropolitan University, and game designer Jason Rohrer's  Project December, which enabled users to converse with language-model representations of loved ones. Early commercial projects such as Eternime, founded by Marius Ursache, also popularized the notion of interactive digital immortality.
Scholars have proposed frameworks and critiques addressing the ethics of these technologies.  Tomasz Hollanek and Katarzyna Nowaczyk-Basińska developed a design-ethics taxonomy distinguishing the data donor, data recipient, and interactant, Edina Harbinja  and  Lilian Edwards formalized the concept of post-mortem privacy, and Carl J. Öhman at the Oxford Internet Institute studied the management of large-scale digital remains. Collectively, these works have shaped emerging policy discussions about ownership, consent, and dignity in digital resurrection technologies.

Cultural and societal impact
GriefBots have prompted broader reflection on mortality and memory in a digital age. They blur boundaries between life and data, raising philosophical questions about identity, authenticity, and what it means to “live on” through algorithms. Cultural acceptance varies: while some view them as expressions of remembrance, others regard them as unsettling or ethically problematic. Concerns have been raised about deadbots' potential for creating psychological harm. Griefbots are considered part of the phenomenon of artificial intimacy.

References
External links
HereAfter AI official website
Augmented Eternity Project
Humanities Washington – When Your Grandpa Is a Bot

See also
Online memorial
Simulacrum
Digital afterlife
Digital immortality
Post-mortem privacy